## Unsupervised and semi-supervised clustering with a siamese triplet: aka "the algorithm is always right"

The idea behind clustering with a siamese triplet is to have the algorithm examine three items and then pick the one item that doesn't fit with the other two. The intuition is that the algorithm will map the inputs to a latent space which will be most compact when similar inputs are close to each other in the latent space.

This repo contains two variations on this idea (`siamclust_binarymodel_keras` and `siamclust_goloss_pytorch`): the first uses a dense model to combine the latent vectors and generate a three-neuron softmax prediction; the second uses a novel loss to minimize the distance between the two nearest vectors while maximizing their distances to the third vector.

Siamese clustering is described more thoroughly in the <a href="https://github.com/small-yellow-duck/titanic-ede/blob/master/unsupervised%20deep%20learning%20with%20enc-dec-enc%20-%202019-07-22.pptx">slides</a> in <a href="https://github.com/small-yellow-duck/titanic-ede">this</a> repo.


<img src="siamclust_binarymodel_keras/images/siam_network.png" width="200">

## Combining latent vectors using a dense model with a 3-neuron softmax output
In `siamclust_binarymodel_keras` the algorithm consists of an encoder, `E`, which maps an input to a vector in the latent space, and a model, `M`, which takes the magnitude of the differences between the vectors, `|E(X_j) - E(X_k)|, |E(X_i) - E(X_k)|, |E(X_i) - E(X_j)|` and predicts a 3-neuron `softmax` output. The algorithm was originally devised to train by being "always right" ie, if the algorithm predicted an output of `[0.3, 0.5, 0.2]`, then the target was assigned to `[0, 1, 0]`. This doesn't result in a training loss with a sensible trajectory or in the creation of latent representations of the MNIST data set. The algorithm was then modified to work in a semi-supervised way by augmenting one of the input images with a small rotation or translation and forcing the target to correspond to the image that not one of the `[X_i, A(X_i)]` pair.


<img src="siamclust_binarymodel_keras/images/mnist_siamtriplet2.png" width="200">

The `siamclust_binarymodel_keras` model can group MNIST digits into reasonable clusters as long as about 1/8 of the `[X_i, X_j, X_k]` triplets contain `[X_i, A(X_i)]` pairs which are explicitly labeled - ie,  `[X_i, X_j, A(X_i)] -> [0, 1, 0]`. (A "reasonable" cluster is one in which similar-looking digits are grouped together - note that the algorithm likes to group 7's with a dash through the vertical stroke seperately from 7's without. Ditto 0's with a slash and `0`'s that look more like O's, as well as 1 and l.) Please note that I'm quite relaxed about evaluating the performance of this algorithm: there is doubtless another algorithm with superior accuracy and I'm happy for the goal to be to just to try out a novel idea.

#### Manually defining augmentations is undesirable
However, the process of doing unsupervised learning by pairing items using augmentations is not very desirable because it relies on an independent formulation of the augmentations. It's intuitive to define augmentations such as rotations and translations for images, but it's not clear how to define augmentations for tabular data. In addition, I can imagine augmentations for the MNIST dataset - like switching from a fat pen to a thin pen - which are not defined in an identical way for each pixel in the image the way rotation or translation augmentations are.

I wanted to think of augmentations as being a small step in a random direction in the latent space - a formulation that is consistent with a variational approach in which the encoder maps an input to both a point in the latent space and a variance: a new point is then generated by using the variance to sample a small step in each dimension in the latent space.


I also wondered if the process of defining augmentations is a process that requires generative capacity and not just the discriminative capacity of an encoder. I imagined an encoder-decoder-encoder network as a way to train an algorithm that could learn augmentations formulated in this way (<a href="https://github.com/small-yellow-duck/encdec">https://github.com/small-yellow-duck/encdec</a>)



#### Noise
The encoder, `E` includes some `Dropout` layers to introduce noise - and training will yield nan losses if there is not a source of noise. The use of a model to combine the three latent vectors to generate a 3-neuron softmax prediction evaluated with binary logloss also does not force the generation of a compact latent space.

Another shortcoming of this formulation of "the algorithm is always right" is that there is no term in the loss to constrain the size of the latent space. In order to avoid this problem - and to make use of a variational formulation - I define a Gaussian Overlap loss which can be used with a variational approach to adding noise to the latent vectors.



#### "Gaussian Overlap: an alternative to the contrastive loss"
The contrastive loss does not pair nicely with variational approaches because the contrastive loss includes a margin term, <img src="https://latex.codecogs.com/svg.latex?m">, which sets the length scale for the latent space. In variational approaches, this length scale is set by a noise term, <img src="https://latex.codecogs.com/svg.latex?\sigma">.

In order to use a variational approach, I propose the Gaussian Overlap loss:

<img src="https://latex.codecogs.com/svg.latex?\mathcal{L}= -t ln(1- erf(|\mu_i - \mu_j|/2)) +  (1-t)  ln(erf(|\mu_i - \mu_j|/2))">,

<img src="https://latex.codecogs.com/svg.latex?t=0"> if <img src="https://latex.codecogs.com/svg.latex?\mu_i"> and <img src="https://latex.codecogs.com/svg.latex?\mu_j"> are embeddings which are meant to describe the same item and <img src="https://latex.codecogs.com/svg.latex?t=1"> the items are not the same.

<img src="https://latex.codecogs.com/svg.latex?\Large&space;\mathcal{L} = -t ln(1- erf(|\mu_i - \mu_j|/2)) +  (1-t)  ln(erf(|\mu_i - \mu_j|/2))" />


## Combining latent vectors using a dense model with a 3-neuron softmax output
One of the reasons that the algorithm described above might need to rely on trios containing an augmented pair `[X_i, X_j, A(X_i)]` with an explicit label is that the parameters in `M` need to be learned along with the parameters in the encoder, `E`. One way to avoid needing to use `M` to combine the latent vectors in order to generate the 3-neuron softmax output would to just calculate which of the latent vector pairs is closest together and then update the encoder by making that pair closer together and the other two pairs further apart.

One possibility for doing this would be to use the contrastive loss.

Should the comparison of two latent vectors, `mu_0, mu_1` also include the 'spreadiness' parameters, `sigma_0, sigma_1`?

